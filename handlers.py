#!/usr/bin/env python3
"""
å¤„ç†å™¨æ¨¡å—
åŒ…å«æ–‡ä»¶å¤„ç†ã€å…ƒæ•°æ®å¤„ç†å’Œä¸‹è½½é˜¶æ®µçš„å¤„ç†å‡½æ•°
"""

import argparse
from pathlib import Path
from typing import Optional

import aiofiles
import aiofiles.os as aos

from downloader import Downloader
from core import (
    DownloaderException,
    NonRecoverableErrorException,
    MaxRetriesExceededException,
    FFmpegException,
)
from subtitles import SubtitleProcessor
from utils import is_media_file, extract_audio_if_needed, sanitize, console, log


async def process_local_file(sub_proc: SubtitleProcessor, file_path: str) -> None:
    """å¤„ç†æœ¬åœ°åª’ä½“æ–‡ä»¶ç”ŸæˆAIå­—å¹•ã€‚

    Args:
        sub_proc (SubtitleProcessor): å­—å¹•å¤„ç†å™¨å®ä¾‹ã€‚
        file_path (str): æœ¬åœ°åª’ä½“æ–‡ä»¶è·¯å¾„ã€‚
    """
    media_path = Path(file_path)
    if not is_media_file(media_path):
        console.print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {media_path.suffix}", style="bold red")
        return

    file_prefix = sanitize(media_path.stem)
    log.info(f"â–¶ï¸ (æœ¬åœ°æ–‡ä»¶) å¼€å§‹å¤„ç†: {file_prefix}")
    media_dir = media_path.parent.resolve()

    try:
        audio_path = await extract_audio_if_needed(media_path, media_dir)
        if not audio_path:
            return

        await sub_proc.process_item(file_prefix, audio_path, output_folder=media_dir)

        if audio_path != media_path and audio_path.name.endswith("_extracted.wav"):
            await aos.remove(audio_path)
            console.print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {audio_path.name}", style="dim")

        console.print(f"âœ… å­—å¹•ç”Ÿæˆå®Œæˆ: {media_path.name}", style="bold green")
    except (OSError, PermissionError) as e:
        log.error(f"æ— æ³•è®¿é—®æœ¬åœ°æ–‡ä»¶ {media_path.name}: {e}")
    except Exception as e:
        log.error(f"å¤„ç†æœ¬åœ°æ–‡ä»¶ {media_path.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)


async def save_info(folder: Path, prefix: str, url: str, dlr) -> None:
    """ä¿å­˜è§†é¢‘ä¿¡æ¯ä¸ºæ–‡æœ¬æ–‡ä»¶ã€‚

    ç›´æ¥ä»yt-dlpè·å–è§†é¢‘ä¿¡æ¯å¹¶ç”Ÿæˆå¯è¯»çš„.txtæ–‡ä»¶ï¼Œä¸ä¾èµ–.info.jsonã€‚

    Args:
        folder (Path): ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        prefix (str): æ–‡ä»¶å‰ç¼€ã€‚
        url (str): è§†é¢‘URLã€‚
        dlr: ä¸‹è½½å™¨å®ä¾‹ã€‚
    """
    try:
        # æ„å»ºè·å–ä¿¡æ¯çš„å‘½ä»¤
        info_cmd = [
            "yt-dlp",
            "--ignore-config",
            "--no-warnings",
            "--no-color",
            "--dump-json",
            "--no-download",
        ]
        if dlr.cookies_file:
            info_cmd.extend(["--cookies", dlr.cookies_file])
        info_cmd.append(url)

        # æ‰§è¡Œå‘½ä»¤è·å–ä¿¡æ¯
        import asyncio

        process = await asyncio.create_subprocess_exec(
            *info_cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await process.communicate()

        if process.returncode == 0 and stdout:
            import json

            info = json.loads(stdout.decode())

            # ç”Ÿæˆ.txtæ–‡ä»¶
            txt_path = folder / f"{prefix}.txt"
            async with aiofiles.open(txt_path, "w", encoding="utf-8") as f:
                await f.write(f"è§†é¢‘æ ‡é¢˜: {info.get('title', 'N/A')}\n")
                await f.write(f"è§†é¢‘URL: {info.get('webpage_url', 'N/A')}\n")
                await f.write(f"UPä¸»: {info.get('uploader', 'N/A')}\n")
                file_size_mb = "N/A"
                if isinstance(info.get("filesize_approx"), (int, float)):
                    file_size_mb = f"{info['filesize_approx'] / (1000 * 1000):.2f} MB"
                await f.write(f"è§†é¢‘å¤§å°: {file_size_mb}\n")
                await f.write(f"è§†é¢‘åˆ†è¾¨ç‡: {info.get('resolution', 'N/A')}\n")
                await f.write(f"è§†é¢‘æ—¶é•¿: {info.get('duration_string', 'N/A')}\n")

                # æ·»åŠ æè¿°ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                description = info.get("description", "")
                if description:
                    await f.write(
                        f"\nç®€ä»‹:\n{description[:500]}{'...' if len(description) > 500 else ''}\n"
                    )

            console.print(f"ğŸ“„ ä¿¡æ¯æ–‡ä»¶å·²ç”Ÿæˆ: {txt_path.name}", style="bold cyan")
        else:
            log.warning(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {prefix}")

    except Exception as e:
        log.error(f"ç”Ÿæˆä¿¡æ¯æ–‡ä»¶å¤±è´¥ '{prefix}': {e}", exc_info=True)


async def process_metadata_phase(dlr: Downloader, url: str, prefix: str) -> None:
    """å¤„ç†å…ƒæ•°æ®é˜¶æ®µã€‚

    ä¸‹è½½è§†é¢‘å…ƒæ•°æ®å¹¶ç”Ÿæˆä¿¡æ¯æ–‡ä»¶ã€‚

    Args:
        dlr (Downloader): ä¸‹è½½å™¨å®ä¾‹ã€‚
        url (str): è§†é¢‘URLã€‚
        prefix (str): æ–‡ä»¶å‰ç¼€ã€‚

    Raises:
        Exception: å½“å…ƒæ•°æ®å¤„ç†å¤±è´¥æ—¶ã€‚
    """
    try:
        await dlr.download_metadata(url, prefix)
        await save_info(dlr.download_folder, prefix, url, dlr)
    except (DownloaderException, IOError, OSError) as e:
        log.error(f"å…ƒæ•°æ®å¤„ç†é˜¶æ®µå¤±è´¥ '{prefix}': {e}")
        raise
    except Exception as e:
        log.error(f"å…ƒæ•°æ®å¤„ç†é˜¶æ®µå‘ç”ŸæœªçŸ¥é”™è¯¯ '{prefix}': {e}", exc_info=True)
        raise


async def process_download_phase(
    dlr: Downloader,
    sub_proc: Optional[SubtitleProcessor],
    url: str,
    prefix: str,
    args: argparse.Namespace,
) -> None:
    """å¤„ç†ä¸‹è½½é˜¶æ®µã€‚

    æ ¹æ®æŒ‡å®šæ¨¡å¼ä¸‹è½½è§†é¢‘å’Œ/æˆ–éŸ³é¢‘ï¼Œå¹¶å¤„ç†AIå­—å¹•ç”Ÿæˆã€‚

    Args:
        dlr (Downloader): ä¸‹è½½å™¨å®ä¾‹ã€‚
        sub_proc (Optional[SubtitleProcessor]): å­—å¹•å¤„ç†å™¨å®ä¾‹ã€‚
        url (str): è§†é¢‘URLã€‚
        prefix (str): æ–‡ä»¶å‰ç¼€ã€‚
        args (argparse.Namespace): å‘½ä»¤è¡Œå‚æ•°ã€‚
    """
    try:
        vid_path = None
        aud_path = None

        # å¤„ç†è§†é¢‘ä¸‹è½½ - ä¼˜å…ˆé‡‡ç”¨æ™ºèƒ½ä¸‹è½½æ¨¡å¼
        if args.mode in ["video", "both"]:
            console.print(f"ğŸ¬ æ­£åœ¨å‡†å¤‡æ™ºèƒ½ä¸‹è½½: {prefix}", style="bold blue")
            try:
                # å°è¯•ä½¿ç”¨æ™ºèƒ½ä¸‹è½½ç­–ç•¥
                vid_path = await dlr.download_with_smart_strategy(url, prefix)
            except Exception as e:
                console.print(f"âš ï¸  æ™ºèƒ½ä¸‹è½½å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}", style="yellow")
                vid_path = await dlr.download_and_merge(url, prefix)

        # å¤„ç†çº¯éŸ³é¢‘ä¸‹è½½
        if args.mode == "audio":
            console.print(f"ğŸµ æ­£åœ¨å‡†å¤‡ä¸‹è½½éŸ³é¢‘: {prefix}", style="bold blue")
            aud_path = await dlr.download_audio_directly(url, prefix)

        # å¤„ç†bothæ¨¡å¼ä¸‹çš„éŸ³é¢‘åœ¨çº¿ä¸‹è½½
        if args.mode == "both":
            console.print(f"ğŸµ æ­£åœ¨åœ¨çº¿ä¸‹è½½éŸ³é¢‘: {prefix}_audio", style="bold blue")
            # bothæ¨¡å¼ç»Ÿä¸€é‡‡ç”¨åœ¨çº¿ä¸‹è½½éŸ³é¢‘ï¼Œæ·»åŠ _audioåç¼€
            aud_path = await dlr.download_audio_directly(url, f"{prefix}_audio")

            # å¤„ç†AIå­—å¹•
            if args.ai_subs and aud_path and sub_proc:
                await sub_proc.process_item(prefix, aud_path)
        elif args.mode == "audio" and args.ai_subs and aud_path and sub_proc:
            # çº¯éŸ³é¢‘æ¨¡å¼ä¸‹çš„AIå­—å¹•å¤„ç†
            await sub_proc.process_item(prefix, aud_path)
        elif args.ai_subs and vid_path and sub_proc:
            # videoæ¨¡å¼ä¸‹å¦‚æœéœ€è¦AIå­—å¹•ï¼Œä½¿ç”¨è§†é¢‘æ–‡ä»¶
            await sub_proc.process_item(prefix, vid_path)

    except (
        NonRecoverableErrorException,
        MaxRetriesExceededException,
        FFmpegException,
    ) as e:
        log.error(f"âŒ å¤„ç†é¡¹ç›® '{prefix}' å¤±è´¥: {e}")
    except DownloaderException as e:
        log.error(f"âŒ å¤„ç†é¡¹ç›® '{prefix}' æ—¶å‘ç”ŸæœªçŸ¥ä¸‹è½½é”™è¯¯: {e}")
    finally:
        await dlr.cleanup_temp_files(prefix)


async def process_item(
    dlr: Downloader,
    sub_proc: Optional[SubtitleProcessor],
    url: str,
    prefix: str,
    args: argparse.Namespace,
) -> None:
    """å®Œæ•´çš„é¡¹ç›®å¤„ç†æµç¨‹ã€‚

    åŒ…æ‹¬å…ƒæ•°æ®ä¸‹è½½å’Œåª’ä½“æ–‡ä»¶ä¸‹è½½ä¸¤ä¸ªé˜¶æ®µã€‚

    Args:
        dlr (Downloader): ä¸‹è½½å™¨å®ä¾‹ã€‚
        sub_proc (Optional[SubtitleProcessor]): å­—å¹•å¤„ç†å™¨å®ä¾‹ã€‚
        url (str): è§†é¢‘URLã€‚
        prefix (str): æ–‡ä»¶å‰ç¼€ã€‚
        args (argparse.Namespace): å‘½ä»¤è¡Œå‚æ•°ã€‚
    """
    log.info(f"â–¶ï¸ (é¡¹ç›®) å¼€å§‹å¤„ç†: {prefix}")

    # å…ƒæ•°æ®é˜¶æ®µ
    await process_metadata_phase(dlr, url, prefix)

    # ä¸‹è½½é˜¶æ®µ
    await process_download_phase(dlr, sub_proc, url, prefix, args)
