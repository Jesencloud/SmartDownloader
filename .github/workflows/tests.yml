# .github/workflows/tests.yml

name: Python Application CI

# 触发器：在推送到主分支或创建拉取请求时运行
on:
  push:
    branches: [ "main", "master" ]
  pull_request:
    branches: [ "main", "master" ]

# Concurrency control: cancel in-progress runs on the same branch/PR
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true


jobs:
  # Job 0: 运行静态代码分析和格式化检查
  lint:
    name: Lint & Format Check
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.11"] # 仅需在一个版本上运行
    timeout-minutes: 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install ruff
      run: pip install ruff

    - name: Run linter (ruff)
      run: ruff check .

    - name: Check formatting (ruff)
      run: ruff format --check .

  # Job 1: 运行快速的单元测试和不依赖外部服务的集成测试
  unit-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11"]
    timeout-minutes: 10 # 为作业设置10分钟的超时

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        # 缓存 pip 的下载目录
        path: ~/.cache/pip
        # 缓存的 key，当 requirements.txt 变化时，缓存会失效
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run unit and integration tests
      run: |
        pytest --cov=core --cov=web --cov-report=xml -m "not e2e" -v
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        token: ${{ secrets.CODECOV_TOKEN }} # 需要在GitHub仓库设置中添加这个secret
        file: ./coverage.xml
        flags: unittests

  # Job 2: 运行需要实时服务的端到端测试
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    # 在 lint 和 unit-tests 成功后运行
    needs: [lint, unit-tests]
    # 为节省时间，仅在一个 Python 版本上运行 E2E 测试
    timeout-minutes: 15 # 为E2E测试设置更长的超时
    strategy:
      matrix:
        python-version: ["3.11"] # 保持在一个Python版本上
        redis-version: ["6", "7"] # 在多个Redis版本上测试
      fail-fast: false # 即使一个组合失败，也继续运行其他组合

    # 为此作业中的所有步骤设置环境变量
    env:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND_URL: redis://redis:6379/0

    # 定义此作业所需的服务容器
    services:
      # 'redis' 是服务的主机名
      redis:
        image: redis:${{ matrix.redis-version }}
        # 添加健康检查以确保 Redis 完全启动后再继续
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports: ["6379:6379"]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install Redis client
      run: |
        sudo apt-get update && sudo apt-get install -y redis-tools

    - name: Start Celery worker in background
      run: |
        # 确保 Redis 服务可用
        echo "Waiting for Redis to be available..."
        while ! redis-cli -h localhost ping | grep PONG; do
          echo "Redis not available yet, sleeping..."
          sleep 2
        done
        echo "Redis is up and running!"

        # 设置环境变量和Python路径
        export CELERY_BROKER_URL=redis://localhost:6379/0
        export CELERY_RESULT_BACKEND_URL=redis://localhost:6379/0
        export PYTHONPATH="${GITHUB_WORKSPACE}:$PYTHONPATH"
        
        # 检查Python能否导入我们的模块
        echo "Testing module imports..."
        python -c "import web.celery_app; print('✅ Celery app imported successfully')"
        
        # 启动 Celery worker 并将日志输出到文件，方便调试
        echo "Starting Celery worker..."
        # 在CI环境中使用简化配置，只监听默认队列
        python -m celery -A web.celery_app worker --loglevel=debug --hostname=e2e-worker@%h -Q celery --without-gossip --without-mingle --without-heartbeat > celery_worker.log 2>&1 &
        
        # 记录worker进程ID
        CELERY_PID=$!
        echo "Celery worker started with PID: $CELERY_PID"
        
        # 等待Celery worker启动
        echo "Waiting for Celery worker to start..."
        sleep 8

    - name: Start FastAPI server in background
      run: |
        # 启动 FastAPI 服务器并将日志输出到文件，方便调试
        echo "FastAPI server started. Logs will be in uvicorn.log"
        uvicorn web.main:app --host 0.0.0.0 --port 8000 > uvicorn.log 2>&1 &


        
    - name: Wait for server to be ready
      run: |
        echo "Waiting for server to be ready..."
        # 等待最多30秒，直到服务器的根端点返回成功的HTTP状态码
        # 使用 curl -sSf:
        # -s: silent mode
        # -S: show error even with -s
        # -f: fail silently (no output) on HTTP errors (returns non-zero exit code)
        for i in {1..30}; do
          if curl -sSf http://127.0.0.1:8000/ > /dev/null; then
            echo "✅ FastAPI Server is up and running!"
            exit 0
          fi
          sleep 1
        done
        echo "❌ Server did not become ready in 30 seconds."
        exit 1

    - name: Wait for Celery worker to be ready
      run: |
       set -o pipefail
       echo "Waiting for Celery worker to be responsive..."
       
       # 添加环境变量以确保Celery使用正确的broker
       export CELERY_BROKER_URL=redis://localhost:6379/0
       export CELERY_RESULT_BACKEND_URL=redis://localhost:6379/0
       export PYTHONPATH="${GITHUB_WORKSPACE}:$PYTHONPATH"
       
       # 首先检查worker日志中是否有启动成功的迹象
       echo "Checking worker startup logs..."
       if [ -f celery_worker.log ]; then
         echo "--- Current worker log ---"
         tail -n 20 celery_worker.log
         echo "--- End of worker log ---"
       fi
       
       for i in {1..25}; do
         echo "Attempt $i/25: Testing Celery worker connectivity..."
         
         # 使用更长的超时时间和更宽松的检测条件
         echo "Testing ping command..."
         PING_RESULT=$(timeout 15 python -m celery -A web.celery_app -b redis://localhost:6379/0 inspect ping --timeout 10 2>&1 || echo "ping_failed")
         echo "Ping result: $PING_RESULT"
         
         # 检查是否有任何worker响应（不仅仅是特定主机名）
         if echo "$PING_RESULT" | grep -E "(pong|ready)" > /dev/null; then
           echo "✅ Celery worker is responsive!"
           
           # 验证worker注册的队列
           echo "Checking registered queues..."
           QUEUE_RESULT=$(timeout 15 python -m celery -A web.celery_app -b redis://localhost:6379/0 inspect active_queues --timeout 10 2>&1 || echo "queue_check_failed")
           echo "Queue result: $QUEUE_RESULT"
           
           if echo "$QUEUE_RESULT" | grep -E "celery" > /dev/null; then
             echo "✅ Worker is monitoring the celery queue."
           else
             echo "⚠️ Worker responsive but celery queue not found. Continuing anyway..."
           fi
           exit 0
         else
           echo "Worker not responsive yet (attempt $i/25)"
           echo "Ping result was: $PING_RESULT"
           
           # 显示最新的日志
           if [ -f celery_worker.log ]; then
             echo "--- Last 5 lines of worker log ---"
             tail -n 5 celery_worker.log
           fi
           
           # 检查进程是否还在运行
           if pgrep -f "celery.*worker" > /dev/null; then
             echo "Worker process is still running..."
           else
             echo "❌ Worker process not found! Restarting..."
             # 重新启动worker
             export CELERY_BROKER_URL=redis://localhost:6379/0
             export CELERY_RESULT_BACKEND_URL=redis://localhost:6379/0
             python -m celery -A web.celery_app worker --loglevel=debug --hostname=e2e-worker@%h -Q celery --without-gossip --without-mingle --without-heartbeat >> celery_worker.log 2>&1 &
             sleep 3
           fi
         fi
         sleep 2
       done
       
       echo "❌ Celery worker did not become ready in 50 seconds."
       echo "--- Final Celery Worker Log ---"
       cat celery_worker.log || echo "No worker log found"
       echo "--- Final connectivity test ---"
       timeout 15 python -m celery -A web.celery_app -b redis://localhost:6379/0 inspect ping --timeout 10 || true
       echo "--- Final Redis status ---"
       redis-cli -h localhost ping || true
       exit 1

    - name: Run end-to-end tests
      run: |
        # 仅运行标记为 e2e 的测试
        pytest --cov=core --cov=web --cov-report=xml -m "e2e" -v
        
    - name: Upload E2E coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml
        flags: e2etests # 为E2E测试报告设置一个独立的标志

    - name: 集群信息 (调试)
      if: always()  # 总是执行，用于调试
      run: |
        echo "Celery 集群信息:"
        celery -A web.celery_app -b redis://localhost:6379/0 status  # 获取 Celery 集群状态
        echo "=========================="
        echo "Redis 信息:"
        redis-cli -h localhost info  # 获取 Redis 信息
